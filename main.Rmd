---
title: "R Notebook"
output:
  html_notebook: default
  pdf_document: default
---
sturgesovo pravidlo
```{r}
#install.packages("corrplot")
#install.packages("car")
```

```{r}
library(dplyr)
data <- read.csv(".\\dataset\\data.csv")
```
ZDROJ:https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks
```{r}
glimpse(data)
unique(is.na(data))
```


```{r}
length(data$name)
length(unique(data$name))
n_occur <- data.frame(table(data$name))
n_occur[n_occur$Freq > 1,]
```
Dataset neobsahuje ziadne NaN hodnoty.
```{r}
rel_date_data = data.frame(chr=apply(data,2,nchar)[,15])
rel_date_data %>% group_by(chr) %>% summarize(count=n())
```
Jedina nekonzistencia sa nachadza v stlpci release_date.Navyse sme pri preverovani teorie, ze stare pesnicky nie su popularne narazili na modernu elektronicku hudbu , co sme aj neskor overili z inych zdrojov(wikipedia, datum umrtia spevaka, youtube release na oficialnom kanali) a zistili sme ze chybne udaje pochadzaju priamo zo spotify. 
Nazvy autorov a piesni su obacas necitatelne zrejme kvoli pouzitiu inej abecedy. Kedze sa chceme zamerat na popularitu piesni a vplyv numerickych hudobnych atributov na nu, tak dataset mozeme pouzit a nazvy nemusime opravovat. 
```{r}
```
```{r}

```


```{r}
```

```{r}
library(tidyverse)
my_plots <- lapply(names(data), function(var_x){
  p <- 
    ggplot(data) +
    aes_string(var_x)

  if(is.numeric(data[[var_x]])) {
    p <- p + geom_density()
    plot(p)
  } 

})

num_data <- subset(data, select = -year) %>% select(where(is.numeric))
```
Pri vykresleni rozdeleni sme zistili, ze atributy ako danceability, energy, tempo a valence maju normalne rozdelenie. 
Rozdelenie pri duration nam ukazalo, ze sa tu nachadza dost outlierov, ktore kedze ide bud o velmi, kratke zanamy alebo dlhe remixy a audioknihy, ktore chceme odstranit. 
Dalej popularity  ma prevahu nulovych hodnot co vsak nemusi byt zle, alebo si to nemisu ziadat opravu, pretoze je bezne ze sa na vrchole drzia vzdy len komercne najuspesnejsi umelci v porovnani s ktorymi maju zvysne menej zname kapaly a tvorcovia mnohonasobne mensiu popularitu a pocet posluchacov.
```{r}
#data %>%
#  group_by(year) %>%
#  summarise(mean_energy = mean(energy, na.rm = TRUE), mean_loudness = mean(loudness, na.rm = TRUE), mean_popularity = mean(popularity, na.rm = TRUE))

#src: https://www.tutorialspoint.com/r/r_mean_median_mode.htm
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}

maxVal <- function(dataset) sapply(dataset, max, na.rm = TRUE)
minVal <- function(dataset) sapply(dataset, min, na.rm = TRUE)
meanVal <- function(dataset) sapply(dataset, mean, na.rm = TRUE)
standDev <- function(dataset) sapply(dataset, sd, na.rm = TRUE)
medVal <- function(dataset) sapply(dataset, median, na.rm = TRUE)
modVal <- function(dataset) sapply(dataset, getmode)
varVal <- function(dataset) sapply(dataset, var, na.rm = TRUE)
#boxplot
#sapply(num_data, function(x) boxplot(x))

maxVal(data)
minVal(data)
meanVal(data)
standDev(data)
medVal(data)
modVal(data)
varVal(data)

library(car)
qqPlot(num_data$valence)

boxplot(num_data$energy, main="energy")
nums <- unlist(lapply(data, is.numeric))  
#data[ , nums]

colMeans(data[ , nums], na.rm = FALSE)
apply(data[ , nums],2,median)
```

```{r}
library(corrr)
data[ , nums] %>% correlate() %>% focus(popularity)
```
```{r}
glimpse(num_data)
library(corrplot)
corrplot(cor(num_data),type="upper")
```
HYPOTEZY:
Kedze chceme predpovedat co potrtebuje mat piesen aby bola popularna, nasu hypotezu budeme zakladat na datach s ktorymi najviac koreluje. Popularita rastie so zvysujucou sa enrgiou, pozitivitou(valence), hlucnostou(loudness), tanecnostou(danceability) a klesajucou akusticnostou a instrumentalnostou.
```{r}
boxplot(num_data$energy, main="energy")
boxplot(num_data$acousticness, main="acousticness")
boxplot(num_data$loudness, main="loudness")$stats[c(1, 5), ]
boxplot(num_data$instrumentalnes, main="instrumentalnes")$stats[c(1, 5), ]
boxplot(num_data$duration_ms, main="duration MS")$stats[c(1, 5), ]
#value of whiskers later used for threshold

```
Aby sme si ukázali tvar distribúcie, stredné hodnoty a variabilitu nad atribútmi, na ktoré sme sa chceli zamerať(korelujúce s popularitou) vykreslili sme si ich boxploty. Ďalej sme pomocou thresholdu odstránili príliš krátke a príliš dlhé nahrávky, čím sme odstránili outlierov pozostávajúcich z dlhých mixov, audiokníh a pod. Thresholdové hodnoty sme získali z whiskers boxplotu a ostali nam tak pesničky medzi 17 sekund a cca 7 min. Pri ostatných sme outlierov neodstranovali pretože nevieme zaručiť, že outlierové hodnoty by nám neboli prospešné alebo neboli správne zadané alebo odmerané.
```{r}
num_data_thr <- num_data[num_data$duration_ms>17000 & num_data$duration_ms<415093,]
summary(num_data)
p <- 
    ggplot(num_data) +
    aes_string("duration_ms")
    p <- p + geom_density()
    plot(p)
```

```{r}
length(num_data)
print(str(length(num_data$duration_ms)), str(length(num_data_thr$duration_ms)))
print(str(length(num_data$duration_ms)-length(num_data_thr$duration_ms)))
p <- 
    ggplot(num_data_thr) +
    aes_string("duration_ms")
    p <- p + geom_density()
    plot(p)
```
Ako môžeme vidieť po odstránení dostaneme rozdelenie v tvare podobnom normálnemu, pričom najčastejšia hodnota je niekde okolo 3,5 minúty. Thresholdom sme odstránili 10057 záznamov.

```{r}
num_data_thrPop <- num_data_thr[num_data_thr$popularity>0,]
corrplot(cor(num_data_thrPop),type="upper")
corrplot(cor(num_data_thr),type="upper")
#t.test(rnorm(num_data$energy), rnorm(num_data$popularity))
```
V rámci experimentov sme skúsili odstrániť dáta, ktoré mali zaznamenanú nulovú popularitu s tým, že sme chceli pozrieť výlučne na nahrávky s nenulovou popularitou a porovnať aká bude ich korelácia. Zamerali sme sa znova hlavne na korelácie medzi popularitou a zvyškom a zmeny boli minimálne čo teda znamená, že môžme nechať všetky nakolko by nám zameranie sa na nenulové nijako nepomohlo.

```{r}
dt = sort(sample(nrow(num_data_thr), nrow(num_data_thr)*.8))
train<-num_data_thr[dt,]
test<-num_data_thr[-dt,]
```


```{r}
modelPopEn = lm(popularity~energy, data = train)
modelPopAc = lm(popularity~acousticness, data = train)
modelPopLo = lm(popularity~loudness, data = train)
modelPopIns = lm(popularity~instrumentalness, data = train)
pairs(train$popularity ~ train$energy + train$acousticness + train$loudness + train$instrumentalness, panel=function(x,y){
  points(x,y)
  abline(lm(y~x), col='red')})
```
```{r}
modelPop4 = lm(train$popularity~train$energy + train$acousticness + train$loudness + train$instrumentalness)
```


```{r}
summary(modelPopEn)#ok
summary(modelPopAc)#ok ale zly vplyv
summary(modelPopLo)#OK
summary(modelPopIns)#ok ale zly vplyv
summary(modelPop4)
```
Na základe regresných modelov zamietame nulovú hypotézu pre všetky navrhnuté hypotézy, kedže z modelov môžeme jasne vidieť, že atribúty a popularita majú medzi sebou vztah (t-value je daleko od 0 a p-value je ovela menšie ako 0.5)

Zaroveň vidime, že chyba je približne na úrovni od 19.5 do 21 čo v našom prípade znamená taktiež percentuálna chyba kedže popularitu máme v intervale od 0 do 100. Preto sme sa rozhodli vyskúšať aj kvadraticku regresiu.
```{r}
train$energy2 <- train$energy^2
train$acousticness2 <- train$acousticness^2
train$loudness2 <- train$loudness^2
train$instrumentalness2 <- train$instrumentalness^2

modelQPopEn = lm(popularity~energy+energy2, data = train)
modelQPopAc = lm(popularity~acousticness+acousticness2, data = train)
modelQPopLo = lm(popularity~loudness+loudness2, data = train)
modelQPopIns = lm(popularity~instrumentalness+instrumentalness2, data = train)
pairs(train$popularity ~ train$energy2 + train$acousticness2 + train$loudness2 + train$instrumentalness2, panel=function(x,y){
  points(x,y)
  abline(lm(y~x), col='red')})
```

```{r}
summary(modelQPopEn)#ok
summary(modelQPopAc)#ok ale zly vplyv
summary(modelQPopLo)#OK
summary(modelQPopIns)#ok ale zly vplyv
```
Kvadratická regresia ako možeme vidieť vyššie niekde mierne zlepšila no niekde zase mierne zhoršila chybu. Aj keď sa nám nepodarilo tieto chyby výrazne znížit rozhodli sme sa pre každú hypotézu tieto dve metódy porovnať aj s predikovanými hodnotami.

```{r}
energyValues <- seq(0, 1, 0.01)

energyQPredict <- predict(modelQPopEn,newdata = list(energy=energyValues, energy2 = energyValues^2))

energyPredict <- predict(modelPopEn,newdata = test)

plot(test$energy, test$popularity)

lines(energyValues, energyQPredict, col='green')

lines(test$energy, energyPredict, col='red')
```
Zelena čiara kvadratický model má chybu 20.48 a červený lineárny model 20.65. Oba modely predikujú v najhustejšie osadenom priestore, no ako môžeme vidieť kvadratický model viac kopíruje tvar dát čo sa ukázalo aj na jeho nižšej chybe. Data sú pravdepodobne príliš rozptýlené aby sa mohol model lepšie nafitovať.

```{r}
acousticnessValues <- seq(0, 1, 0.01)

acousticnessQPredict <- predict(modelQPopAc,newdata = list(acousticness=acousticnessValues, acousticness2 = acousticnessValues^2))

acousticnessPredict <- predict(modelPopAc,newdata = test)

plot(test$acousticness, test$popularity)

lines(acousticnessValues, acousticnessQPredict, col='green')

lines(test$acousticness, acousticnessPredict, col='red')
```
Zelena čiara kvadratický model má chybu 19.54 a červený lineárny model 20.02. Oba modely predikujú v najhustejšie osadenom priestore, no ako môžeme vidieť kvadratický model viac kopíruje tvar dát čo sa znovu ukázalo aj na jeho nižšej chybe.


```{r}
loudnessValues <- seq(min(test$loudness), max(test$loudness), 0.01)

loudnessQPredict <- predict(modelQPopLo,newdata = list(loudness=loudnessValues, loudness2 = loudnessValues^2))

loudnessPredict <- predict(modelPopLo,newdata = test)

plot(test$loudness, test$popularity)

lines(loudnessValues, loudnessQPredict, col='green')

lines(test$loudness, loudnessPredict, col='red')
```
Zelena krivka kvadratický model má chybu 20.44 a červený lineárny model 20.62. Lineárny model podľa grafu vyzerá tento krát lepšie no kvadratický mal aj napriek tomu nižšiu chybu čo je zrejme zapríčinené zhodou aj v riedkých datach v ľavej polovici grafu.

```{r}
instrumentalnessValues <- seq(min(test$instrumentalness), max(test$instrumentalness), 0.01)

instrumentalnessQPredict <- predict(modelQPopIns,newdata = list(instrumentalness=instrumentalnessValues, instrumentalness2 = instrumentalnessValues^2))

instrumentalnessPredict <- predict(modelPopIns,newdata = test)

plot(test$instrumentalness, test$popularity)

lines(instrumentalnessValues, instrumentalnessQPredict, col='green')

lines(test$instrumentalness, instrumentalnessPredict, col='red')
```
Zelena krivka kvadratický model má chybu 20.99 a červený lineárny model 21.03. Pri tomto grafe môžeme vidieť, že dátam nevyhovuje ani jeden z modelov a majú aj vyššiu chybu oproti ostatným. Zrejme by bola vhodnejšia regresia zložitejšou funkciou.



BAYES


```{r}
#install.packages("R2OpenBUGS")
#install.packages("rjags")
#install.packages("coda")
#install.packages("MCMCvis")
library(R2OpenBUGS)
library(rjags)
library(coda)
library(MCMCvis)

mod = function(){
  #priors
  b0~dnorm(0,.001)
  Z~dnorm(0,.001)

  sigma~dunif(0,100)
  tau<-1/(sigma*sigma)
  
  
  #likelihood
  for(i in 1:length(energy)){
    mu[i]<-b0+100*exp(-Z*energy[i])
    Pop[i]~dnorm(mu[i], tau)
    Pop_pred[i]~dnorm(mu[i], tau)
  }

}
```

```{r}
# write model
model.file="model.txt"
write.model(mod,model.file)

# no initial values
inits<-NULL

# what parameters we want to track
params = c("tau","Z", "b0", "Pop_pred")

## hyperparameters
# number of iterations
ni = 1000
# burn in interval
nb = 100
# thinning interval
nt = 1
# number of chains
nc = 3

dataBay <- subset(test, select = c("popularity","energy"))[sample(nrow(test), 5000),]

# compile model
jmod = jags.model(file = model.file, data = dataBay, n.chains = nc, inits = inits, n.adapt = 1000)

# iterate through jmod for the extent of the burn-in
update(jmod, n.iter=nb, by=1)

# draw samples from the posterior for params, given MCMC hyperparameters
post = coda.samples(jmod, params, n.iter = ni, thin = nt)

# diagnostic evaluation of posterior samples
MCMCtrace(post, params = c('b0','Z'), pdf=F)

# objectively assess convergence with gelmans diagnostic
#gelman.diag(post)

# get summary of posterior samples for two parameters
MCMCsummary(post, params = c('b0','Z'), digits=2)
```
```{r}
# get samples from posteriors
samples = jags.samples(jmod,c('b0', 'Z', 'Pop_pred'), length(dataBay$energy))
```


```{r}
# take the mean of each group of samples
posterior_means = apply(samples$Pop_pred,1,mean)

# plot posterior means versus observed values
plot(dataBay$popularity, posterior_means, ylab='Predicted Popularity', xlab='Observed Popularity')
lines(seq(1,3500),seq(1,3500), col='red', lwd=2, cex=3)
```
Predikcia pomocou bayesa sa nám nevydarila, vznikli nám hodnody veľmi vzdialené od reálnych hodnôt(>4e+56). 
